{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch  # Import the PyTorch library\n",
        "import torch.nn as nn  # Import the neural network module from PyTorch\n",
        "import torch.optim as optim  # Import the optimization module from PyTorch\n"
      ],
      "metadata": {
        "id": "3v-Fowo99SBL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare custom dataset\n",
        "\n",
        "# Define tensors A and B with specified values and data type\n",
        "A = torch.tensor([[10,20],[30,40]], dtype=torch.float32)\n",
        "B = torch.tensor([[50,60],[70,80]], dtype=torch.float32)\n",
        "\n",
        "# Concatenate tensors A and B along dimension 0 to create input features\n",
        "X = torch.cat((A, B), 0)  # features\n",
        "\n",
        "# Create tensor Y representing the labels\n",
        "Y = torch.tensor([0,0,1,1])  # label\n"
      ],
      "metadata": {
        "id": "1y45kdnc9yWt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define neural network architecture\n",
        "\n",
        "class custom_neural_network(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        Initialize the custom neural network.\n",
        "\n",
        "        Args:\n",
        "            input_size (int): Size of the input features.\n",
        "            hidden_size (int): Size of the hidden layer.\n",
        "            output_size (int): Size of the output.\n",
        "        \"\"\"\n",
        "        super(custom_neural_network, self).__init__()\n",
        "        # Define layers\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)  # Input layer to hidden layer\n",
        "        self.linear2 = nn.Linear(hidden_size, output_size)  # Hidden layer to output layer\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        Forward pass method for the neural network.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor to the neural network.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor from the neural network.\n",
        "        \"\"\"\n",
        "        lin = self.linear1(input)  # Linear transformation from input to hidden layer\n",
        "        output = nn.functional.relu(lin)  # Applying ReLU activation function for introducing non-linearity\n",
        "        pred = self.linear2(output)  # Linear transformation from hidden to output layer\n",
        "        return pred\n"
      ],
      "metadata": {
        "id": "R-kZ9Xagu71l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss criterion using Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer using the Adam optimizer\n",
        "# It optimizes the parameters of the model using the gradients computed during backpropagation\n",
        "# lr=0.001 sets the learning rate to 0.001\n",
        "\n",
        "# Define the input, hidden, and output sizes for the neural network\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 2\n",
        "\n",
        "# Instantiate a model with the specified input, hidden, and output sizes\n",
        "model = custom_neural_network(input_size, hidden_size, output_size)\n",
        "\n",
        "# Set up the optimizer to update the parameters of the model during training\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "Bg-27igw1MN9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "\n",
        "# Loop through each epoch for training\n",
        "for epoch in range(epochs):\n",
        "    # Zero the gradients to prevent accumulation from previous iterations\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "    outputs = model(X)\n",
        "\n",
        "    # Compute the loss using the specified criterion\n",
        "    loss = criterion(outputs, Y)\n",
        "\n",
        "    # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the weights of the model\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss every 50 epochs\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXq6DXfGBWnl",
        "outputId": "8c8a2332-f045-4da5-f319-ff291780648b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/500, Loss: 2.4432497024536133\n",
            "Epoch 100/500, Loss: 0.5802291035652161\n",
            "Epoch 150/500, Loss: 0.5449532270431519\n",
            "Epoch 200/500, Loss: 0.5144392848014832\n",
            "Epoch 250/500, Loss: 0.4810105562210083\n",
            "Epoch 300/500, Loss: 0.4453328847885132\n",
            "Epoch 350/500, Loss: 0.40826839208602905\n",
            "Epoch 400/500, Loss: 0.37093275785446167\n",
            "Epoch 450/500, Loss: 0.3345632255077362\n",
            "Epoch 500/500, Loss: 0.3002699613571167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model evaluation\n",
        "# Use torch.no_grad() to disable gradient calculation during inference\n",
        "with torch.no_grad():\n",
        "    # Pass input data X through the model to obtain predictions\n",
        "    outputs = model(X)\n",
        "    # Extract the predicted class indices by taking the maximum value along the second dimension\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    # Print the predicted class indices\n",
        "    print('Predicted:', predicted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lArVNOtOFgCn",
        "outputId": "6dd56961-d773-4435-a1db-0048e065a695"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: tensor([0, 0, 1, 1])\n"
          ]
        }
      ]
    }
  ]
}